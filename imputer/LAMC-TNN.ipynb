{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-Rank Autoregressive Tensor Completion (LATC)\n",
    "\n",
    "This notebook shows how to implement a LATC (with truncated nuclear norm) imputer on some real-world traffic data sets. To overcome the problem of missing values within multivariate time series data, this method takes into account both low-rank structure and time series regression. For an in-depth discussion of LATC, please see [1].\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=\"black\">\n",
    "<b>[1]</b> Xinyu Chen, Mengying Lei, Nicolas Saunier, Lijun Sun (2021). <b>A Low-Rank Autorgressive Tensor Completion for Spatiotemporal Traffic Data Imputation</b>. arXiv:xxxx.xxxxx. <a href=\"https://arxiv.org/abs/xxxx.xxxxx\" title=\"PDF\"><b>[PDF]</b></a> \n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LATC-imputer kernel\n",
    "\n",
    "We start by introducing some necessary functions that relies on `Numpy`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>ten2mat</code>:</b> <font color=\"black\">Unfold tensor as matrix by specifying mode.</font></li>\n",
    "<li><b><code>mat2ten</code>:</b> <font color=\"black\">Fold matrix as tensor by specifying dimension (i.e, tensor size) and mode.</font></li>\n",
    "<li><b><code>svt_tnn</code>:</b> <font color=\"black\">Implement the process of Singular Value Thresholding (SVT).</font></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')\n",
    "\n",
    "def mat2ten(mat, dim, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(dim.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(dim[index]), order = 'F'), 0, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svt_tnn(mat, tau, theta):\n",
    "    [m, n] = mat.shape\n",
    "    if 2 * m < n:\n",
    "        u, s, v = np.linalg.svd(mat @ mat.T, full_matrices = 0)\n",
    "        s = np.sqrt(s)\n",
    "        idx = np.sum(s > tau)\n",
    "        mid = np.zeros(idx)\n",
    "        mid[: theta] = 1\n",
    "        mid[theta : idx] = (s[theta : idx] - tau) / s[theta : idx]\n",
    "        return (u[:, : idx] @ np.diag(mid)) @ (u[:, : idx].T @ mat)\n",
    "    elif m > 2 * n:\n",
    "        return svt_tnn(mat.T, tau, theta).T\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices = 0)\n",
    "    idx = np.sum(s > tau)\n",
    "    vec = s[: idx].copy()\n",
    "    vec[theta : idx] = s[theta : idx] - tau\n",
    "    return u[:, : idx] @ np.diag(vec) @ v[: idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>compute_mape</code>:</b> <font color=\"black\">Compute the value of Mean Absolute Percentage Error (MAPE).</font></li>\n",
    "<li><b><code>compute_rmse</code>:</b> <font color=\"black\">Compute the value of Root Mean Square Error (RMSE).</font></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "> Note that $$\\mathrm{MAPE}=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\left|y_{i}-\\hat{y}_{i}\\right|}{y_{i}} \\times 100, \\quad\\mathrm{RMSE}=\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}},$$ where $n$ is the total number of estimated values, and $y_i$ and $\\hat{y}_i$ are the actual value and its estimation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae(var, var_hat):\n",
    "    return np.mean(np.abs(var - var_hat))\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to create $\\boldsymbol{\\Psi}_{0},\\boldsymbol{\\Psi}_{1},\\ldots,\\boldsymbol{\\Psi}_{d}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve as spsolve\n",
    "\n",
    "def generate_Psi(dim_time, time_lags):\n",
    "    Psis = []\n",
    "    max_lag = np.max(time_lags)\n",
    "    for i in range(len(time_lags) + 1):\n",
    "        row = np.arange(0, dim_time - max_lag)\n",
    "        if i == 0:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag\n",
    "        else:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag - time_lags[i - 1]\n",
    "        data = np.ones(dim_time - max_lag)\n",
    "        Psi = sparse.coo_matrix((data, (row, col)), shape = (dim_time - max_lag, dim_time))\n",
    "        Psis.append(Psi)\n",
    "    return Psis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psi_0:\n",
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "\n",
      "Psi_1:\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "Psi_2:\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example\n",
    "dim_time = 5\n",
    "time_lags = np.array([1, 3])\n",
    "Psis = generate_Psi(dim_time, time_lags)\n",
    "print('Psi_0:')\n",
    "print(Psis[0].toarray())\n",
    "print()\n",
    "print('Psi_1:')\n",
    "print(Psis[1].toarray())\n",
    "print()\n",
    "print('Psi_2:')\n",
    "print(Psis[2].toarray())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea behind LATC-imputer is to approximate partially observed data with both low-rank structure and time series dynamics. The following `imputer` kernel includes some necessary inputs:\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>dense_tensor</code>:</b> <font color=\"black\">This is an input which has the ground truth for validation. If this input is not available, you could use <code>dense_tensor = sparse_tensor.copy()</code> instead.</font></li>\n",
    "<li><b><code>sparse_tensor</code>:</b> <font color=\"black\">This is a partially observed tensor which has many missing entries.</font></li>\n",
    "<li><b><code>time_lags</code>:</b> <font color=\"black\">Time lags, e.g., <code>time_lags = np.array([1, 2, 3])</code>. </font></li>\n",
    "<li><b><code>alpha</code>:</b> <font color=\"black\">Weights for tensors' nuclear norm, e.g., <code>alpha = np.ones(3) / 3</code>. </font></li>\n",
    "<li><b><code>rho</code>:</b> <font color=\"black\">Learning rate for ADMM, e.g., <code>rho = 0.0005</code>. </font></li>\n",
    "<li><b><code>lambda0</code>:</b> <font color=\"black\">Weight for time series regressor, e.g., <code>lambda0 = 5 * rho</code></font></li>\n",
    "<li><b><code>epsilon</code>:</b> <font color=\"black\">Stop criteria, e.g., <code>epsilon = 0.0001</code>. </font></li>\n",
    "<li><b><code>maxiter</code>:</b> <font color=\"black\">Maximum iteration to stop algorithm, e.g., <code>maxiter = 100</code>. </font></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(dense_mat, sparse_mat, time_lags, rho0, lambda0, theta, epsilon, maxiter, K = 3, pos_missing = None):\n",
    "    \"\"\"Low-Rank Autoregressive Matrix Completion, LAMC-imputer.\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_mat.shape)\n",
    "    d = len(time_lags)\n",
    "    max_lag = np.max(time_lags)\n",
    "    #pos_missing = np.where(sparse_mat == 0)\n",
    "    #pos_test = np.where((dense_mat != 0) & (sparse_mat == 0))\n",
    "    pos_test = pos_missing\n",
    "    dense_test = dense_mat[pos_test]\n",
    "    del dense_mat\n",
    "    \n",
    "    T = np.zeros(dim)\n",
    "    Z = sparse_mat.copy()\n",
    "    Z[pos_missing] = np.mean(sparse_mat[sparse_mat != 0])\n",
    "    A = 0.001 * np.random.rand(dim[0], d)\n",
    "    Psis = generate_Psi(dim[1], time_lags)\n",
    "    iden = sparse.coo_matrix((np.ones(dim[1]), (np.arange(0, dim[1]), np.arange(0, dim[1]))), shape = (dim[1], dim[1]))\n",
    "    it = 0\n",
    "    ind = np.zeros((d, dim[1] - max_lag), dtype = np.int_)\n",
    "    for i in range(d):\n",
    "        ind[i, :] = np.arange(max_lag - time_lags[i], dim[1] - time_lags[i])\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    rho = rho0\n",
    "    while True:\n",
    "        B = []\n",
    "        for m in range(dim[0]):\n",
    "            Psis0 = Psis.copy()\n",
    "            for i in range(d):\n",
    "                Psis0[i + 1] = A[m, i] * Psis[i + 1]\n",
    "            B.append(Psis0[0] - sum(Psis0[1 :]))\n",
    "        for k in range(K):\n",
    "            rho = min(rho * 1.05, 1e5)\n",
    "            X = svt_tnn(Z - T / rho, 1 / rho, theta)\n",
    "            temp0 = rho / lambda0 * (X + T / rho)\n",
    "            mat = np.zeros(dim)\n",
    "            for m in range(dim[0]):\n",
    "                mat[m, :] = spsolve(B[m].T @ B[m] + rho * iden / lambda0, temp0[m, :])\n",
    "            Z[pos_missing] = mat[pos_missing]\n",
    "            T = T + rho * (X - Z)\n",
    "        for m in range(dim[0]):\n",
    "            Vm = Z[m, ind].T\n",
    "            A[m, :] = np.linalg.pinv(Vm) @ Z[m, max_lag :]\n",
    "        tol = np.linalg.norm((X - last_mat), 'fro') / snorm\n",
    "        last_mat = X.copy()\n",
    "        it += 1\n",
    "        if it % 200 == 0:\n",
    "            print('Iter: {}'.format(it))\n",
    "            print('Tolerance: {:.6}'.format(tol))\n",
    "            print('MAE: {:.6}'.format(compute_mae(dense_test, X[pos_test])))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_test, X[pos_test])))\n",
    "            print()\n",
    "        if (tol < epsilon and tol != 0) or (it >= maxiter):\n",
    "            break\n",
    "\n",
    "    print('Total iteration: {}'.format(it))\n",
    "    print('Tolerance: {:.6}'.format(tol))\n",
    "    print('Imputation MAE: {:.6}'.format(compute_mae(dense_test, X[pos_test])))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(dense_test, X[pos_test])))\n",
    "    print()\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We use `spslove` of `scipy.sparse.linalg` for updating $\\boldsymbol{Z}$ because computing the inverse of a large matrix directly is computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def read_raw_data(name):\n",
    "    data = pd.read_csv(name, index_col=0, parse_dates=True)\n",
    "    columns_name = list(data.columns)\n",
    "    index = data.index\n",
    "    ##minmax-score\n",
    "    norlizer = MinMaxScaler().fit(data)\n",
    "    data = norlizer.transform(data)\n",
    "    return data, columns_name, index, norlizer\n",
    "\n",
    "def evaluate(raw_data, prediction, mask=None, seasonal=None):\n",
    "    #rmse = RMSE_Metric(raw_data, miss_data, np.concatenate((miss_data[0,:].reshape(1,-1), prediction), axis=0), missing_flag=missing_flag)\n",
    "    #print('RMSE:', rmse)\n",
    "    prediction = prediction[mask].flatten()\n",
    "    missed_raw_data = raw_data[mask].flatten()\n",
    "    if seasonal is not None:\n",
    "        missed_seasonal = seasonal[mask].flatten()\n",
    "        concated_prediction += missed_seasonal\n",
    "        missed_raw_data += missed_seasonal\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(missed_raw_data, prediction))\n",
    "    mae = mean_absolute_error(missed_raw_data, prediction)\n",
    "    #mape = mean_absolute_percentage_error(missed_raw_data, concated_prediction)\n",
    "    #print('RMSE2:', rmse2)\n",
    "    return (rmse, mae), prediction#, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from pathlib import Path\n",
    "np.random.seed(1000)\n",
    "\n",
    "test_len = 12\n",
    "#log_dir = Path('../logs/baselines/')\n",
    "#log_dir.mkdir(exist_ok=True)\n",
    "root_dir = Path('../..')\n",
    "\n",
    "datasets = {\n",
    "    'AU': '../data/open-data/HK2012-2018/Australia.csv',\n",
    "    'PH': '../data/open-data/HK2012-2018/Philippine.csv',\n",
    "    'SG': '../data/open-data/HK2012-2018/Singapore.csv',\n",
    "    'TH': '../data/open-data/HK2012-2018/Thailand.csv',\n",
    "    'UK': '../data/open-data/HK2012-2018/United_Kingdom.csv',\n",
    "    'US': '../data/open-data/HK2012-2018/United_States.csv',\n",
    "}\n",
    "masks = {\n",
    "    'random5': '../data/masks/random5.npy',\n",
    "    'random10': '../data/masks/random10.npy',\n",
    "    'block5': '../data/masks/block5.npy',\n",
    "    'block10': '../data/masks/block10.npy'\n",
    "}\n",
    "\n",
    "dataset = 'AU'\n",
    "mask_name = 'random5'\n",
    "\n",
    "data, columns_name, index, norlizer = read_raw_data(root_dir/datasets[dataset])\n",
    "mask = np.load(root_dir/masks[mask_name]).astype(bool)\n",
    "miss_data = data.copy()\n",
    "miss_data[mask] = 0\n",
    "train_miss_data = miss_data[:-test_len].T\n",
    "eval_real_data = data[:-test_len].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "5\n",
      "Total iteration: 88\n",
      "Tolerance: 9.38856e-05\n",
      "Imputation MAE: 0.132277\n",
      "Imputation RMSE: 0.204676\n",
      "\n",
      "Running time: 32 seconds\n",
      "\n",
      "0.2\n",
      "5\n",
      "Total iteration: 88\n",
      "Tolerance: 8.68472e-05\n",
      "Imputation MAE: 0.132319\n",
      "Imputation RMSE: 0.204618\n",
      "\n",
      "Running time: 32 seconds\n",
      "\n",
      "1\n",
      "5\n",
      "Total iteration: 88\n",
      "Tolerance: 9.25411e-05\n",
      "Imputation MAE: 0.132242\n",
      "Imputation RMSE: 0.204608\n",
      "\n",
      "Running time: 32 seconds\n",
      "\n",
      "5\n",
      "5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m epsilon \u001b[39m=\u001b[39m \u001b[39m1e-4\u001b[39m\n\u001b[1;32m     11\u001b[0m maxiter \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m---> 12\u001b[0m mat_hat \u001b[39m=\u001b[39m imputer(eval_real_data, train_miss_data, time_lags, rho, lambda0, theta, epsilon, maxiter, pos_missing\u001b[39m=\u001b[39;49mmask[:\u001b[39m-\u001b[39;49mtest_len]\u001b[39m.\u001b[39;49mT)\n\u001b[1;32m     13\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRunning time: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m(end \u001b[39m-\u001b[39m start))\n",
      "Cell \u001b[0;32mIn[63], line 39\u001b[0m, in \u001b[0;36mimputer\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     37\u001b[0m mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(dim)\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(dim[\u001b[39m0\u001b[39m]):\n\u001b[0;32m---> 39\u001b[0m     mat[m, :] \u001b[39m=\u001b[39m spsolve(B[m]\u001b[39m.\u001b[39;49mT \u001b[39m@\u001b[39;49m B[m] \u001b[39m+\u001b[39m rho \u001b[39m*\u001b[39m iden \u001b[39m/\u001b[39m lambda0, temp0[m, :])\n\u001b[1;32m     40\u001b[0m Z[pos_missing] \u001b[39m=\u001b[39m mat[pos_missing]\n\u001b[1;32m     41\u001b[0m T \u001b[39m=\u001b[39m T \u001b[39m+\u001b[39m rho \u001b[39m*\u001b[39m (X \u001b[39m-\u001b[39m Z)\n",
      "File \u001b[0;32m~/.conda/envs/ntf1/lib/python3.8/site-packages/scipy/sparse/base.py:560\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m isscalarlike(other):\n\u001b[1;32m    558\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mScalar operands are not allowed, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39muse \u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 560\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__mul__\u001b[39;49m(other)\n",
      "File \u001b[0;32m~/.conda/envs/ntf1/lib/python3.8/site-packages/scipy/sparse/base.py:480\u001b[0m, in \u001b[0;36mspmatrix.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m other\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    479\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mdimension mismatch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 480\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mul_sparse_matrix(other)\n\u001b[1;32m    482\u001b[0m \u001b[39m# If it's a list or whatever, treat it like a matrix\u001b[39;00m\n\u001b[1;32m    483\u001b[0m other_a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(other)\n",
      "File \u001b[0;32m~/.conda/envs/ntf1/lib/python3.8/site-packages/scipy/sparse/compressed.py:530\u001b[0m, in \u001b[0;36m_cs_matrix._mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    521\u001b[0m fn \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(_sparsetools, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_matmat\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    522\u001b[0m fn(M, N, np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr, dtype\u001b[39m=\u001b[39midx_dtype),\n\u001b[1;32m    523\u001b[0m    np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices, dtype\u001b[39m=\u001b[39midx_dtype),\n\u001b[1;32m    524\u001b[0m    \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m    other\u001b[39m.\u001b[39mdata,\n\u001b[1;32m    528\u001b[0m    indptr, indices, data)\n\u001b[0;32m--> 530\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m((data, indices, indptr), shape\u001b[39m=\u001b[39;49m(M, N))\n",
      "File \u001b[0;32m~/.conda/envs/ntf1/lib/python3.8/site-packages/scipy/sparse/compressed.py:106\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 106\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_format(full_check\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/ntf1/lib/python3.8/site-packages/scipy/sparse/compressed.py:157\u001b[0m, in \u001b[0;36m_cs_matrix.check_format\u001b[0;34m(self, full_check)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    154\u001b[0m     warn(\u001b[39m\"\u001b[39m\u001b[39mindices array has non-integer dtype (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mname), stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m idx_dtype \u001b[39m=\u001b[39m get_index_dtype((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindptr, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices))\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr, dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[1;32m    159\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices, dtype\u001b[39m=\u001b[39midx_dtype)\n",
      "File \u001b[0;32m~/.conda/envs/ntf1/lib/python3.8/site-packages/scipy/sparse/sputils.py:165\u001b[0m, in \u001b[0;36mget_index_dtype\u001b[0;34m(arrays, maxval, check_contents)\u001b[0m\n\u001b[1;32m    162\u001b[0m     arrays \u001b[39m=\u001b[39m (arrays,)\n\u001b[1;32m    164\u001b[0m \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays:\n\u001b[0;32m--> 165\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(arr)\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mcan_cast(arr\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mint32):\n\u001b[1;32m    167\u001b[0m         \u001b[39mif\u001b[39;00m check_contents:\n",
      "File \u001b[0;32m~/.conda/envs/ntf1/lib/python3.8/site-packages/numpy/core/_asarray.py:16\u001b[0m, in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmultiarray\u001b[39;00m \u001b[39mimport\u001b[39;00m array\n\u001b[1;32m     12\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39masarray\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39masanyarray\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mascontiguousarray\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39masfortranarray\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrequire\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m ]\n\u001b[0;32m---> 16\u001b[0m \u001b[39m@set_module\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39masarray\u001b[39m(a, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     18\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert the input to an array.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m array(a, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, order\u001b[39m=\u001b[39morder)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for c in [1/10, 1/5, 1, 5, 10]:\n",
    "    for theta in [5]:\n",
    "        start = time.time()\n",
    "        #time_lags = np.arange(1, 12)\n",
    "        time_lags = np.array([1,12])\n",
    "        rho = 1e-4\n",
    "        lambda0 = c * rho\n",
    "        print(c)\n",
    "        print(theta)\n",
    "        epsilon = 1e-4\n",
    "        maxiter = 100\n",
    "        mat_hat = imputer(eval_real_data, train_miss_data, time_lags, rho, lambda0, theta, epsilon, maxiter, pos_missing=mask[:-test_len].T)\n",
    "        end = time.time()\n",
    "        print('Running time: %d seconds'%(end - start))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
